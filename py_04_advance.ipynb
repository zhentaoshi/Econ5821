{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Advanced Python\n",
    "## ECON5170 Computational Methods in Economics\n",
    "#### Author: Zhentao Shi\n",
    "#### Date: March 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced R (Python)\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this lecture, we will talk about efficient computation in R (Python).\n",
    "\n",
    "*  **R is a vector-oriented language. In most cases, vectorization speeds up computation**.\n",
    "*  We turn to more CPUs for parallel execution to save time if there is no more room to optimize the code to improve the speed.\n",
    "*  Clusters are accessed remotely. Communicating with a remote cluster is different from operating a local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Despite mathematical equivalence, various ways of calculation can perform distinctively in terms of computational speed.\n",
    "\n",
    "Does computational speed matter?\n",
    "For a job that takes less than a minutes, the time difference is not a big deal.\n",
    "For modern economic structural estimation problems commonly seen in industrial organization, a single estimation can take up to a week. For those problems code optimization is essential.\n",
    "\n",
    "Other computational intensive procedures include bootstrap, simulated maximum likelihood and simulated method of moments. Even if a single execution does not take much time, repeating such a procedure for thousands of replications will consume a non-trivial duration.\n",
    "\n",
    "Of course, optimizing code takes human time. It is a balance of human time and machine time.\n",
    "\n",
    "__Example__\n",
    "\n",
    "The heteroskedastic-robust variance for the OLS regression is\n",
    "$$(X'X)^{-1} X'\\hat{e}\\hat {e}'X (X'X)^{-1}$$\n",
    "The difficult part is $X'\\hat{e}\\hat {e}'X=\\sum_{i=1}^n \\hat{e}_i^2 x_i x_i'$.\n",
    "There are at least 4 mathematically equivalent ways to compute this term.\n",
    "\n",
    "1.  literally sum over $i=1,\\dots,n$ one by one.\n",
    "2.  $X' \\mathrm{diag}(\\hat{e}^2) X$, with a dense central matrix.\n",
    "3.  $X' \\mathrm{diag}(\\hat{e}^2) X$, with a sparse central matrix.\n",
    "4.  Do cross product to `X*e_hat`. It takes advantage of the element-by-element operation.\n",
    "\n",
    "We first generate the data of binary response and regressors. Due to the discrete nature of the dependent variable, the error term in the linear probability model is heteroskedastic. It is necessary to use the heteroskedastic-robust variance to consistently estimate the asymptotic variance of the OLS estimator. The code chunk below estimates the coefficients and obtains the residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-4yjgc0zc because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix \n",
    "import random\n",
    "import datetime\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpm(n):\n",
    "    # estimation in a linear probability model\n",
    "\n",
    "    # set the parameters\n",
    "    b0 = np.array([-1, 1])\n",
    "\n",
    "    # generate the data\n",
    "    e = np.random.normal(size=n)\n",
    "    X = np.hstack((np.ones((n, 1)), np.random.normal(size=(n, 1))))\n",
    "    Y = (X @ b0 + e >= 0)\n",
    "\n",
    "    # OLS estimation\n",
    "    bhat = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "\n",
    "    # calculate the t-value\n",
    "    bhat2 = bhat[1]  # parameter we want to test\n",
    "    e_hat = Y - X @ bhat\n",
    "    return X, e_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the 4 estimators for the same data, and compare the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 50 , Rep = 1000 , opt = 1 , time = 0.9605729579925537 \n",
      "\n",
      "n = 50 , Rep = 1000 , opt = 2 , time = 0.10442757606506348 \n",
      "\n",
      "n = 50 , Rep = 1000 , opt = 3 , time = 0.4029197692871094 \n",
      "\n",
      "n = 50 , Rep = 1000 , opt = 4 , time = 0.15856575965881348 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy.sparse import diags\n",
    "\n",
    "# an example of robust variance matrix.\n",
    "# compare the implementation via matrix and vectorization.\n",
    "\n",
    "# n = 5000; Rep = 10 # large matrix\n",
    "\n",
    "n = 50; Rep = 1000 # small matrix\n",
    "\n",
    "\n",
    "\n",
    "for opt in range(1, 5):\n",
    "    pts0 = time.time()\n",
    "    \n",
    "    # initialize the matrix for computing the variance-covariance matrix\n",
    "    XXe2 = np.zeros((2, 2))\n",
    "\n",
    "    # loop over the replications and compute the variance-covariance matrix\n",
    "    for iter in range(Rep):\n",
    "        np.random.seed(iter)\n",
    "        data = lpm(n)\n",
    "        X = data[0]\n",
    "        e_hat = data[1]\n",
    "        # compute the variance-covariance matrix using element-by-element calculation\n",
    "        if opt == 1:\n",
    "            for i in range(n):\n",
    "                XXe2 += e_hat[i]**2 * np.matrix(X[i,]).T @ np.matrix(X[i,])\n",
    "        \n",
    "        # compute the variance-covariance matrix using matrix multiplication with dense matrices\n",
    "        elif opt == 2:\n",
    "            e_hat2_M = np.zeros((n, n))\n",
    "            np.fill_diagonal(e_hat2_M, e_hat**2)\n",
    "            XXe2 = np.matrix(X).T @ np.matrix(e_hat2_M) @ np.matrix(X)\n",
    "        \n",
    "        # compute the variance-covariance matrix using matrix multiplication with sparse matrices\n",
    "        elif opt == 3:\n",
    "            e_hat2_M = diags(e_hat**2, format='csr')\n",
    "            XXe2 = X.T @ e_hat2_M @ X\n",
    "        \n",
    "        # compute the variance-covariance matrix using vectorization with no waste\n",
    "        elif opt == 4:\n",
    "            e_hat = e_hat.reshape((-1, 1))\n",
    "            Xe = np.matrix(X).T * np.matrix(e_hat)\n",
    "            XXe2 = Xe @ Xe.T\n",
    "        \n",
    "        # compute the robust variance-covariance matrix using the sample size\n",
    "        XX_inv = np.linalg.inv(X.T @ X)\n",
    "        sig_B = XX_inv @ XXe2 @ XX_inv\n",
    "        \n",
    "    print(\"n =\", n, \", Rep =\", Rep, \", opt =\", opt, \", time =\", time.time() - pts0, \"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results with n = 50 and Rep = 1000**\n",
    "\n",
    "n = 50 , Rep = 1000 , opt = 1 , time = 0.5873687267303467 \n",
    "\n",
    "n = 50 , Rep = 1000 , opt = 2 , time = 0.07624149322509766 \n",
    "\n",
    "n = 50 , Rep = 1000 , opt = 3 , time = 0.20538115501403809 \n",
    "\n",
    "n = 50 , Rep = 1000 , opt = 4 , time = 0.06907129287719727 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see the difference in running time, though the 4 methods are mathematically the same.\n",
    "When $n$ is small, `matrix` is fast and `Matrix` is slow; the vectorized version is the fastest.\n",
    "When $n$ is big, `matrix` is slow and `Matrix` is fast; the vectorized version is still the fastest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Loop\n",
    "\n",
    "* R evolves for big data\n",
    "* housekeeping is needed in `for` loops\n",
    "* `plyr` simplifies the job and facilitates parallelization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Example\n",
    "\n",
    "* Empirical coverage probability of a Poisson distribution\n",
    "* Write a DIY `CI` for confidence interval\n",
    "\n",
    "This is a standard `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def CI(x):\n",
    "    # x is a numpy array of random variables\n",
    "    n = len(x)\n",
    "    mu = np.mean(x)\n",
    "    sig = np.std(x)\n",
    "    upper = mu + 1.96 / np.sqrt(n) * sig\n",
    "    lower = mu - 1.96 / np.sqrt(n) * sig\n",
    "    return {\"lower\": lower, \"upper\": upper}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a standard `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop without pre-definition takes 0.008306026458740234 seconds\n"
     ]
    }
   ],
   "source": [
    "Rep = 100 # or whatever value you choose\n",
    "sample_size = 100 # or whatever value you choose\n",
    "mu = 10 # or whatever value you choose\n",
    "\n",
    "np.random.seed(1) # set seed for reproducibility\n",
    "out = [] # initialize out as empty list\n",
    "pts0 = time.time() # check time\n",
    "\n",
    "for i in range(Rep):\n",
    "    x = np.random.poisson(mu, size=sample_size)\n",
    "    bounds = CI(x)\n",
    "    out.append((bounds[\"lower\"] <= mu) & (mu <= bounds[\"upper\"]))\n",
    "\n",
    "pts1 = time.time() - pts0 # check time elapsed\n",
    "print(\"loop without pre-definition takes\", pts1, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical loop with an empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop with pre-definition takes 0.008758306503295898 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "Rep = 100 # or whatever value you choose\n",
    "sample_size = 10 # or whatever value you choose\n",
    "mu = 10 # or whatever value you choose\n",
    "\n",
    "np.random.seed(1) # set seed for reproducibility\n",
    "out = np.zeros(Rep, dtype=bool) # pre-define out with appropriate shape\n",
    "pts0 = time.time() # check time\n",
    "\n",
    "for i in range(Rep):\n",
    "    x = np.random.poisson(mu, size=sample_size)\n",
    "    bounds = CI(x)\n",
    "    out[i] = ((bounds[\"lower\"] <= mu) & (mu <= bounds[\"upper\"]))\n",
    "\n",
    "pts1 = time.time() - pts0 # check time elapsed\n",
    "print(\"loop with pre-definition takes\", pts1, \"seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pay attention to the line `out = np.empty(Rep, dtype=bool) `. \n",
    "* Memoery operates differently with or without the container"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `plyr`\n",
    "There is no equivalent module in python for `plyr`, so this part is omitted for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Computing\n",
    "\n",
    "Parallel computing becomes essential when the data size is beyond the storage of a single computer, for example  {% cite li2018embracing %}.\n",
    "Here we explore the speed gain of parallel computing on a multicore machine.\n",
    "\n",
    "Here we explore the speed gain of parallel computing on a multicore machine.\n",
    "\n",
    "The package `multiprocessing` is the choice for parallel computing in Python.\n",
    "Below is the basic structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel loop takes 0.0038094520568847656 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "\n",
    "def parallel_func(i):\n",
    "    # your function code here\n",
    "    # for example:\n",
    "    x = np.random.poisson(mu, size=sample_size)\n",
    "    bounds = CI(x)\n",
    "    return (bounds[\"lower\"] <= mu) & (mu <= bounds[\"upper\"])\n",
    "\n",
    "Rep = 100 # or whatever value you choose\n",
    "mu = 10 # or whatever value you choose\n",
    "sample_size = 10 # or whatever value you choose\n",
    "\n",
    "pool = Pool(2) # open 2 CPUs\n",
    "pts0 = time.time() # check time\n",
    "\n",
    "out = pool.map(parallel_func, range(Rep))\n",
    "\n",
    "pts1 = time.time() - pts0 # check time elapsed\n",
    "print(\"parallel loop takes\", pts1, \"seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Surprisingly, parallel computing runs more slowly\n",
    "  * Each loop can be done in very short time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* code chunk below will tell a different story.\n",
    "  * Time in each loop is non-trivial\n",
    "  * The only difference is `%dopar%` vs. `%do%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-core parallel loop takes 19.011606454849243 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def parallel_func(i):\n",
    "    # your function code here\n",
    "    # for example:\n",
    "    x = np.random.poisson(mu, size=sample_size)\n",
    "    bounds = CI(x)\n",
    "    return (bounds[\"lower\"] <= mu) & (mu <= bounds[\"upper\"])\n",
    "\n",
    "Rep = 200 # or whatever value you choose\n",
    "mu = 10 # or whatever value you choose\n",
    "sample_size = 2000000 # or whatever value you choose\n",
    "\n",
    "# parallel version with 2 cores\n",
    "pool = Pool(2) # open 2 CPUs\n",
    "pts0 = time.time() # check time\n",
    "out = pool.map(parallel_func, range(Rep))\n",
    "print(\"2-core parallel loop takes\", time.time() - pts0 , \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single-core loop takes 36.475889682769775 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# single-core version\n",
    "pts0 = time.time()\n",
    "out = [parallel_func(i) for i in range(Rep)]\n",
    "print(\"single-core loop takes\", time.time() - pts0 , \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have two CPUs running simultaneously, in theory we can cut the time to a half of that on a single CPU. Is that what happening in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing with the `process` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "The result: True\n",
      "[True, True, True, True, True, True, True, True, True, True]\n",
      "empirical coverage probability =  1.0 % \n",
      "\n",
      "The the calculation time is: 0.1193692684173584 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rep = 10\n",
    "sample_size = 1000\n",
    "mu = 2\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "\n",
    "\n",
    "def capture(i,return_dict):\n",
    "    np.random.seed(i)\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    result = ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "    # process_id = os.getpid()\n",
    "    # print(\"Process ID: \" + str(process_id))\n",
    "    print(\"The result: \" + str(result))\n",
    "    return_dict[i]=result\n",
    "\n",
    "pts0 = time.time() # check time\n",
    "\n",
    "manager = mp.Manager()\n",
    "return_dict = manager.dict()\n",
    "jobs = []\n",
    "\n",
    "for i in range(Rep):\n",
    "    p = Process(target=capture, args=(i,return_dict))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "for proc in jobs:\n",
    "    proc.join()\n",
    "\n",
    "print(return_dict.values())\n",
    "\n",
    "stat_cover = np.mean(return_dict.values()) # jobs.count(True)/Rep*100\n",
    "\n",
    "print( \"empirical coverage probability = \", stat_cover, \"% \\n\") # empirical size\n",
    "pts1 = time.time() - pts0 # check time elapse\n",
    "print(\"The the calculation time is:\", pts1, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing with the `pool` class & `apply()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZT comments: the coverage probability is unlike to be true. Need to check the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  0.955 \n",
      "\n",
      "The the calculation time is: 0.17428827285766602 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rep = 200\n",
    "sample_size = 2000\n",
    "mu = 2\n",
    "\n",
    "\n",
    "pts0 = time.time()  # check time\n",
    "\n",
    "def capture(i):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    return ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "\n",
    "# Only allows to run 4 processes at the time\n",
    "pool = mp.Pool(processes=4)\n",
    "\n",
    "# Initiate the multiprocess process wit apply()\n",
    "results = [pool.apply(capture, args=(i,)) for x in range(Rep)]\n",
    "\n",
    "print( \"empirical coverage probability = \", np.mean(results), \"\\n\") # empirical size\n",
    "pts1 = time.time() - pts0 # check time elapse\n",
    "print(\"The the calculation time is:\", pts1, \"\\n\")\n",
    "# print(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing with the `pool` class & `map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical coverage probability =  94.5 \n",
      "\n",
      "The the calculation time is: 0.035188913345336914 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rep = 200\n",
    "sample_size = 2000\n",
    "mu = 2\n",
    "\n",
    "pts0 = time.time()  # check time\n",
    "def capture(i):\n",
    "    x = np.random.poisson(mu, sample_size)\n",
    "    bounds = CI(x)\n",
    "    return ((bounds['lower'] <= mu) & (mu <= bounds['upper']))\n",
    "    \n",
    "# Only allows to run 4 processes at the time\n",
    "pool = mp.Pool(processes=4)\n",
    "\n",
    "# Initiate the multiprocess process with the map()\n",
    "results = pool.map(capture, range(Rep), )\n",
    "\n",
    "print( \"empirical coverage probability = \", results.count(True)/Rep*100, \"\\n\") # empirical size\n",
    "pts1 = time.time() - pts0 # check time elapse\n",
    "print(\"The the calculation time is:\", pts1, \"\\n\")\n",
    "# print(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Computing\n",
    "\n",
    "Investing money from our own pocket to an extremely powerful laptop to conduct heavy-lifting computational work\n",
    "is unnecessary. (i) We do not run these long jobs every day, it is more cost efficient\n",
    "to share a workhorse. (ii) We cannot keep our laptop always on when we move it\n",
    "around. The right solution is remote computing on a server.\n",
    "\n",
    "No fundamental difference lies between local and remote computing.\n",
    "We prepare the data and code, open a shell for communication, run the code, and collect the results.\n",
    "One potential obstacle is dealing with a command-line-based operation system.\n",
    "Such command line tools is the norm of life two or three decades ago, but today we mostly\n",
    "work in a graphic operating system like Windows or OSX.\n",
    "For Windows users (I am one of them), I recommend [PuTTY](http://www.putty.org/), a shell, and [WinSCP](http://winscp.net/eng/download.php), a graphic interface for input and output.\n",
    "\n",
    "Most servers in the world are running Unix/Linux operation system.\n",
    "Here are a few commands for basic operations.\n",
    "\n",
    "* mkdir\n",
    "* cd\n",
    "* copy\n",
    "* top\n",
    "* screen\n",
    "* ssh user@address\n",
    "* start a program\n",
    "\n",
    "Our department's computation infrastructure has been improving.\n",
    "A server dedicated to  professors is a 16-core machine. I have opened an account for you.\n",
    "You can try out this script on `econsuper`.\n",
    "\n",
    "1. Log in `econsuper.econ.cuhk.edu.hk`;\n",
    "2. Save the code block below as `loop_server.R`, and upload it to the server;\n",
    "3. In a shell, run `R --vanilla <loop_server.R> result_your_name.out`;\n",
    "4. To run a command in the background, add `&` at the end of the above command. To keep it running after closing the console, add `nohup` at the beginning of the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
