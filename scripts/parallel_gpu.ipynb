{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel GPU: CPU vs GPU Performance Comparison\n",
    "\n",
    "This notebook compares CPU and GPU performance for estimating confidence interval coverage rates using Monte Carlo simulation.\n",
    "\n",
    "## Problem Setup\n",
    "- We generate samples from a Poisson distribution with mean Î¼ = 2\n",
    "- For each sample, we compute a 95% confidence interval using the normal approximation\n",
    "- We check whether the true mean falls within the confidence interval\n",
    "- The coverage rate is the proportion of samples where the CI contains the true mean\n",
    "\n",
    "## This Approach\n",
    "- **CPU**: Process each replication sequentially in a loop\n",
    "- **GPU**: Generate all replications and compute coverage in parallel using CuPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "We import:\n",
    "- `time` for measuring execution time\n",
    "- `numpy` for CPU-based numerical computations\n",
    "- `cupy` for GPU-accelerated numerical computations (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:23:29.699257Z",
     "iopub.status.busy": "2026-02-11T12:23:29.698755Z",
     "iopub.status.idle": "2026-02-11T12:23:30.917476Z",
     "shell.execute_reply": "2026-02-11T12:23:30.916976Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "except ImportError:\n",
    "    cp = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Function\n",
    "\n",
    "`ci_bounds(x)` computes the 95% confidence interval bounds for a sample using the normal approximation:\n",
    "- $\\bar{x}$: sample mean\n",
    "- $s$: sample standard deviation\n",
    "- $n$: sample size\n",
    "- Margin of error: $1.96 \\times s / \\sqrt{n}$\n",
    "- Bounds: $[\\bar{x} - \\text{margin}, \\bar{x} + \\text{margin}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:23:30.919449Z",
     "iopub.status.busy": "2026-02-11T12:23:30.919259Z",
     "iopub.status.idle": "2026-02-11T12:23:30.922189Z",
     "shell.execute_reply": "2026-02-11T12:23:30.921898Z"
    }
   },
   "outputs": [],
   "source": [
    "mu = 2\n",
    "\n",
    "def ci_bounds(x):\n",
    "    \"\"\"Compute 95% confidence interval bounds.\"\"\"\n",
    "    n = len(x)\n",
    "    xbar = np.mean(x)\n",
    "    sig = np.std(x)\n",
    "    upper = xbar + 1.96 / np.sqrt(n) * sig\n",
    "    lower = xbar - 1.96 / np.sqrt(n) * sig\n",
    "    return {\"lower\": lower, \"upper\": upper}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Coverage Estimation Functions\n",
    "\n",
    "### `coverage_cpu(rep, n, lam)`\n",
    "- Generates `rep` samples sequentially\n",
    "- For each sample, computes the CI and checks if it contains `lam`\n",
    "- Returns the proportion of covered samples\n",
    "\n",
    "### `coverage_gpu(rep, n, lam)`\n",
    "- Generates all `rep` samples simultaneously as a (rep, n) array\n",
    "- Computes means and standard deviations across all replications in parallel\n",
    "- Checks coverage for all replications at once using vectorized operations\n",
    "- Returns the proportion of covered samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:23:30.923605Z",
     "iopub.status.busy": "2026-02-11T12:23:30.923485Z",
     "iopub.status.idle": "2026-02-11T12:23:30.927420Z",
     "shell.execute_reply": "2026-02-11T12:23:30.927151Z"
    }
   },
   "outputs": [],
   "source": [
    "def coverage_cpu(rep, n, lam):\n",
    "    \"\"\"Estimate coverage rate using CPU.\n",
    "    Generates samples and computes coverage sequentially.\"\"\"\n",
    "    covered_count = 0\n",
    "    for _ in range(rep):\n",
    "        x = np.random.poisson(lam, n)\n",
    "        bounds = ci_bounds(x)\n",
    "        if (bounds[\"lower\"] <= lam) and (lam <= bounds[\"upper\"]):\n",
    "            covered_count += 1\n",
    "    return covered_count / rep\n",
    "\n",
    "def coverage_gpu(rep, n, lam):\n",
    "    \"\"\"Estimate coverage rate using GPU.\n",
    "    All replications are generated and processed in parallel.\"\"\"\n",
    "    x = cp.random.poisson(lam=lam, size=(rep, n))\n",
    "    xbar = cp.mean(x, axis=1)\n",
    "    sig = cp.std(x, axis=1)\n",
    "    margin = (1.96 / np.sqrt(n)) * sig\n",
    "    covered = (xbar - margin <= lam) & (lam <= xbar + margin)\n",
    "    return cp.mean(covered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Experimental Configuration\n",
    "\n",
    "We define:\n",
    "- `Rep`: Number of Monte Carlo replications (100,000)\n",
    "- `sample_size`: Sample size per replication (5)\n",
    "\n",
    "The coverage rate for small samples (n=5) is expected to be below 0.95 because the normal approximation to the Poisson distribution is poor when n is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:23:30.928924Z",
     "iopub.status.busy": "2026-02-11T12:23:30.928625Z",
     "iopub.status.idle": "2026-02-11T12:23:30.931386Z",
     "shell.execute_reply": "2026-02-11T12:23:30.930982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size = 5, replications = 100000:\n"
     ]
    }
   ],
   "source": [
    "# Experimental configuration\n",
    "Rep = 100000\n",
    "sample_size = 5\n",
    "\n",
    "print(f\"Sample size = {sample_size}, replications = {Rep}:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Benchmark\n",
    "\n",
    "We run the CPU version and measure:\n",
    "- Execution time\n",
    "- Estimated coverage rate\n",
    "\n",
    "The CPU version processes each replication sequentially, which is straightforward but slower for large numbers of replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:23:30.955489Z",
     "iopub.status.busy": "2026-02-11T12:23:30.954977Z",
     "iopub.status.idle": "2026-02-11T12:23:34.304883Z",
     "shell.execute_reply": "2026-02-11T12:23:34.304443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CPU Coverage Estimation\n",
      "============================================================\n",
      "CPU sequential run takes 3.3451 seconds\n",
      "CPU coverage = 0.8427\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CPU Coverage Estimation\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "t0 = time.time()\n",
    "out_cpu = coverage_cpu(Rep, sample_size, mu)\n",
    "cpu_time = time.time() - t0\n",
    "\n",
    "print(f\"CPU sequential run takes {cpu_time:.4f} seconds\")\n",
    "print(f\"CPU coverage = {out_cpu:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Benchmark\n",
    "\n",
    "We run the GPU version and measure:\n",
    "- GPU device name\n",
    "- Execution time\n",
    "- Estimated coverage rate\n",
    "\n",
    "The GPU version:\n",
    "1. Generates all replications at once using `cp.random.poisson`\n",
    "2. Computes statistics across all replications in parallel\n",
    "3. Uses `cp.cuda.Stream.null.synchronize()` to ensure all GPU operations complete before timing\n",
    "\n",
    "When CuPy is not available or no GPU is detected, the GPU run is skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:23:34.307443Z",
     "iopub.status.busy": "2026-02-11T12:23:34.307223Z",
     "iopub.status.idle": "2026-02-11T12:23:34.684252Z",
     "shell.execute_reply": "2026-02-11T12:23:34.683700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GPU Coverage Estimation\n",
      "============================================================\n",
      "GPU device: NVIDIA GeForce RTX 3060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU parallel run takes 0.2087 seconds\n",
      "GPU coverage = 0.8440\n"
     ]
    }
   ],
   "source": [
    "if cp is None:\n",
    "    print(\"\\nGPU run skipped: cupy is not installed.\")\n",
    "    gpu_time = None\n",
    "    out_gpu = None\n",
    "else:\n",
    "    try:\n",
    "        n_gpu = cp.cuda.runtime.getDeviceCount()\n",
    "        if n_gpu < 1:\n",
    "            print(\"\\nGPU run skipped: no CUDA device detected.\")\n",
    "            gpu_time = None\n",
    "            out_gpu = None\n",
    "        else:\n",
    "            props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "            gpu_name = props[\"name\"].decode(\"utf-8\")\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"GPU Coverage Estimation\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"GPU device: {gpu_name}\")\n",
    "\n",
    "            t0 = time.time()\n",
    "            out_gpu = coverage_gpu(Rep, sample_size, mu)\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "            gpu_time = time.time() - t0\n",
    "\n",
    "            print(f\"GPU parallel run takes {gpu_time:.4f} seconds\")\n",
    "            print(f\"GPU coverage = {float(out_gpu.get()):.4f}\")\n",
    "    except cp.cuda.runtime.CUDARuntimeError as err:\n",
    "        print(f\"\\nGPU run skipped: {err}\")\n",
    "        gpu_time = None\n",
    "        out_gpu = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "We compare CPU and GPU results:\n",
    "- **Execution Time**: GPU should be significantly faster for large numbers of replications\n",
    "- **Coverage Rate**: Both methods should produce nearly identical results\n",
    "- **Speedup**: Ratio of CPU time to GPU time\n",
    "- **Time Saved**: Actual time difference\n",
    "- **Percentage Faster**: How much faster GPU is compared to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T12:23:34.686995Z",
     "iopub.status.busy": "2026-02-11T12:23:34.686853Z",
     "iopub.status.idle": "2026-02-11T12:23:34.691050Z",
     "shell.execute_reply": "2026-02-11T12:23:34.690745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PERFORMANCE COMPARISON SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Configuration: Sample size = 5, Replications = 100,000\n",
      "\n",
      "Metric                    CPU             GPU             Speedup   \n",
      "----------------------------------------------------------------------\n",
      "Execution Time (s)        3.3451          0.2087          16.03     x\n",
      "Coverage Rate             0.8427          0.8440          -\n",
      "\n",
      "======================================================================\n",
      "GPU Speedup: 16.03x\n",
      "Time Saved: 3.1365 seconds\n",
      "93.8% faster than CPU\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PERFORMANCE COMPARISON SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nConfiguration: Sample size = {sample_size:,}, Replications = {Rep:,}\")\n",
    "print(f\"\\n{'Metric':<25} {'CPU':<15} {'GPU':<15} {'Speedup':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(f\"{'Execution Time (s)':<25} {cpu_time:<15.4f} \", end=\"\")\n",
    "if gpu_time is not None:\n",
    "    speedup = cpu_time / gpu_time\n",
    "    print(f\"{gpu_time:<15.4f} {speedup:<10.2f}x\")\n",
    "else:\n",
    "    print(f\"{'N/A':<15} {'N/A':<10}\")\n",
    "\n",
    "print(f\"{'Coverage Rate':<25} {out_cpu:<15.4f} \", end=\"\")\n",
    "if out_gpu is not None:\n",
    "    print(f\"{float(out_gpu.get()):<15.4f} -\")\n",
    "else:\n",
    "    print(f\"{'N/A':<15} -\")\n",
    "\n",
    "if gpu_time is not None:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"GPU Speedup: {speedup:.2f}x\")\n",
    "    print(f\"Time Saved: {cpu_time - gpu_time:.4f} seconds\")\n",
    "    print(f\"{(cpu_time - gpu_time) / cpu_time * 100:.1f}% faster than CPU\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
