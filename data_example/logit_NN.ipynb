{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplest case of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data for logistic regression with two regressors\n",
    "\n",
    "n = 100\n",
    "\n",
    "x1 = np.random.normal(0, 1, n)\n",
    "x2 = np.random.normal(0, 1, n)\n",
    "\n",
    "# True parameters\n",
    "beta_0 = 0.0  # intercept\n",
    "beta_1 = 1.0  # coefficient for x1\n",
    "beta_2 = -1.0  # coefficient for x2\n",
    "\n",
    "# Compute linear predictor and probability using the logistic function\n",
    "lin_pred = beta_0 + beta_1 * x1 + beta_2 * x2\n",
    "p = 1 / (1 + np.exp(-lin_pred))\n",
    "\n",
    "# Generate binary outcome (y) based on the computed probabilities\n",
    "y = np.random.binomial(1, p, n)\n",
    "\n",
    "# Create a DataFrame with the simulated data\n",
    "logit_data = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our logistic regression data (logit_data) to PyTorch tensors\n",
    "X_logit_tensor = torch.tensor(logit_data[['x1', 'x2']].values, dtype=torch.float32)\n",
    "y_logit_tensor = torch.tensor(logit_data['y'].values.reshape(-1, 1), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a logistic regression model as a neural network with one hidden layer\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, weight_init=None, bias_init=None):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.hidden = nn.Linear(2, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "model = LogisticRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and the optimizer\n",
    "criterion = nn.BCELoss() # binary cross-entropy loss\n",
    "# notice: AI suggested \"BCELogitsLoss\", which was wrong.\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000, Loss: 0.5143\n",
      "Epoch 400/1000, Loss: 0.4970\n",
      "Epoch 600/1000, Loss: 0.4961\n",
      "Epoch 800/1000, Loss: 0.4961\n",
      "Epoch 1000/1000, Loss: 0.4961\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "epochs = 1000  # you can adjust epochs for convergence\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(X_logit_tensor)  # raw scores\n",
    "    loss = criterion(logits, y_logit_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated weights (input layer parameters):\n",
      "hidden.weight: [[ 1.1459869 -1.3353062]]\n",
      "hidden.bias: [-0.02284491]\n",
      "\n",
      "Final LogLoss: 49.6062\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Report the estimated weights (the weights and bias of the one-layer NN)\n",
    "print(\"\\nEstimated weights (input layer parameters):\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data.numpy()}\")\n",
    "\n",
    "# Compute final log loss on the training data\n",
    "# with torch.no_grad():\n",
    "final_loss = n * criterion(model(X_logit_tensor), y_logit_tensor).item()\n",
    "print(f\"\\nFinal LogLoss: {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496062\n",
      "         Iterations 6\n",
      "\n",
      "True parameters:\n",
      "Intercept: 0.0, x1: 1.0, x2: -1.0\n",
      "\n",
      "Estimated parameters:\n",
      "const   -0.022843\n",
      "x1       1.146098\n",
      "x2      -1.335520\n",
      "dtype: float64\n",
      "\n",
      "Log-likelihood: 49.6062\n"
     ]
    }
   ],
   "source": [
    "# Add a constant to the regressors for the intercept\n",
    "X_logit = sm.add_constant(logit_data[['x1', 'x2']])\n",
    "\n",
    "# Fit the logistic regression model using statsmodels\n",
    "logit_model = sm.Logit(logit_data['y'], X_logit).fit()\n",
    "# print(\"Logistic Regression Results Summary:\")\n",
    "# print(logit_model.summary())\n",
    "\n",
    "# Display the true parameters and the estimated coefficients\n",
    "print(\"\\nTrue parameters:\")\n",
    "print(f\"Intercept: {beta_0}, x1: {beta_1}, x2: {beta_2}\")\n",
    "print(\"\\nEstimated parameters:\")\n",
    "print(logit_model.params)\n",
    "# print the value of the log-likelihood function\n",
    "print(f\"\\nLog-likelihood: {-logit_model.llf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
