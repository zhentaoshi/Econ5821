{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PoissonRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.exp(self.linear(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Generate the artificial data\n",
    "\n",
    "n_total = int(20000)\n",
    "K = 100\n",
    "X = np.column_stack((np.ones(n_total), np.random.rand(n_total * (K - 1)).reshape(n_total, K - 1)))\n",
    "b0 = 1.0 * np.ones(K) / K\n",
    "y = np.random.poisson(np.exp(X.dot(b0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "n = len(y)\n",
    "test_indices = random.sample(range(n), round(0.2 * n))\n",
    "\n",
    "y_test = y[test_indices]\n",
    "X_test = X[test_indices, :]\n",
    "\n",
    "y_train = np.delete(y, test_indices)\n",
    "X_train = np.delete(X, test_indices, axis=0)\n",
    "\n",
    "# convert X_train into a pytorch tensor\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PoissonRegression(K)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_nll_loss(y_pred, y_true):\n",
    "    return torch.mean(y_pred - y_true * torch.log(y_pred)) # this is the correct formula. \n",
    "# y_pred is the linear index, y_true is the true value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1003668308258057\n",
      "Epoch 2, Loss: 0.9636091589927673\n",
      "Epoch 3, Loss: 0.8922603726387024\n",
      "Epoch 4, Loss: 0.8599673509597778\n",
      "Epoch 5, Loss: 0.8470344543457031\n",
      "Epoch 6, Loss: 0.8423025012016296\n",
      "Epoch 7, Loss: 0.8406559228897095\n",
      "Epoch 8, Loss: 0.8400800228118896\n",
      "Epoch 9, Loss: 0.8398569822311401\n",
      "Epoch 10, Loss: 0.8397468328475952\n",
      "Epoch 11, Loss: 0.8396721482276917\n",
      "Epoch 12, Loss: 0.8396086096763611\n",
      "Epoch 13, Loss: 0.839548647403717\n",
      "Epoch 14, Loss: 0.8394898772239685\n",
      "Epoch 15, Loss: 0.839431643486023\n",
      "Epoch 16, Loss: 0.8393736481666565\n",
      "Epoch 17, Loss: 0.8393158316612244\n",
      "Epoch 18, Loss: 0.8392581939697266\n",
      "Epoch 19, Loss: 0.8392006754875183\n",
      "Epoch 20, Loss: 0.8391433358192444\n",
      "Epoch 21, Loss: 0.8390861749649048\n",
      "Epoch 22, Loss: 0.8390291929244995\n",
      "Epoch 23, Loss: 0.8389724493026733\n",
      "Epoch 24, Loss: 0.8389157056808472\n",
      "Epoch 25, Loss: 0.8388592004776001\n",
      "Epoch 26, Loss: 0.8388028144836426\n",
      "Epoch 27, Loss: 0.8387466073036194\n",
      "Epoch 28, Loss: 0.8386905193328857\n",
      "Epoch 29, Loss: 0.8386346697807312\n",
      "Epoch 30, Loss: 0.8385788798332214\n",
      "Epoch 31, Loss: 0.8385233879089355\n",
      "Epoch 32, Loss: 0.8384679555892944\n",
      "Epoch 33, Loss: 0.8384127020835876\n",
      "Epoch 34, Loss: 0.8383574485778809\n",
      "Epoch 35, Loss: 0.8383025527000427\n",
      "Epoch 36, Loss: 0.8382478952407837\n",
      "Epoch 37, Loss: 0.8381931185722351\n",
      "Epoch 38, Loss: 0.8381385803222656\n",
      "Epoch 39, Loss: 0.8380842208862305\n",
      "Epoch 40, Loss: 0.8380300998687744\n",
      "Epoch 41, Loss: 0.8379760980606079\n",
      "Epoch 42, Loss: 0.8379220962524414\n",
      "Epoch 43, Loss: 0.837868332862854\n",
      "Epoch 44, Loss: 0.8378148078918457\n",
      "Epoch 45, Loss: 0.8377612829208374\n",
      "Epoch 46, Loss: 0.8377079963684082\n",
      "Epoch 47, Loss: 0.8376548290252686\n",
      "Epoch 48, Loss: 0.8376018404960632\n",
      "Epoch 49, Loss: 0.8375491499900818\n",
      "Epoch 50, Loss: 0.8374963402748108\n",
      "Epoch 51, Loss: 0.8374438285827637\n",
      "Epoch 52, Loss: 0.8373913764953613\n",
      "Epoch 53, Loss: 0.8373390436172485\n",
      "Epoch 54, Loss: 0.8372868895530701\n",
      "Epoch 55, Loss: 0.8372349739074707\n",
      "Epoch 56, Loss: 0.8371831774711609\n",
      "Epoch 57, Loss: 0.8371315002441406\n",
      "Epoch 58, Loss: 0.8370798826217651\n",
      "Epoch 59, Loss: 0.8370286226272583\n",
      "Epoch 60, Loss: 0.8369773626327515\n",
      "Epoch 61, Loss: 0.8369263410568237\n",
      "Epoch 62, Loss: 0.836875319480896\n",
      "Epoch 63, Loss: 0.8368244171142578\n",
      "Epoch 64, Loss: 0.8367737531661987\n",
      "Epoch 65, Loss: 0.836723268032074\n",
      "Epoch 66, Loss: 0.8366729021072388\n",
      "Epoch 67, Loss: 0.8366225957870483\n",
      "Epoch 68, Loss: 0.8365724086761475\n",
      "Epoch 69, Loss: 0.8365225195884705\n",
      "Epoch 70, Loss: 0.836472749710083\n",
      "Epoch 71, Loss: 0.8364229202270508\n",
      "Epoch 72, Loss: 0.8363733887672424\n",
      "Epoch 73, Loss: 0.8363239169120789\n",
      "Epoch 74, Loss: 0.8362747430801392\n",
      "Epoch 75, Loss: 0.8362255692481995\n",
      "Epoch 76, Loss: 0.8361765742301941\n",
      "Epoch 77, Loss: 0.8361276388168335\n",
      "Epoch 78, Loss: 0.8360790014266968\n",
      "Epoch 79, Loss: 0.8360303044319153\n",
      "Epoch 80, Loss: 0.8359819650650024\n",
      "Epoch 81, Loss: 0.8359335064888\n",
      "Epoch 82, Loss: 0.8358853459358215\n",
      "Epoch 83, Loss: 0.8358372449874878\n",
      "Epoch 84, Loss: 0.8357893824577332\n",
      "Epoch 85, Loss: 0.8357415795326233\n",
      "Epoch 86, Loss: 0.8356939554214478\n",
      "Epoch 87, Loss: 0.835646390914917\n",
      "Epoch 88, Loss: 0.8355989456176758\n",
      "Epoch 89, Loss: 0.8355517387390137\n",
      "Epoch 90, Loss: 0.8355047106742859\n",
      "Epoch 91, Loss: 0.8354576230049133\n",
      "Epoch 92, Loss: 0.8354107737541199\n",
      "Epoch 93, Loss: 0.8353639841079712\n",
      "Epoch 94, Loss: 0.8353173732757568\n",
      "Epoch 95, Loss: 0.8352709412574768\n",
      "Epoch 96, Loss: 0.8352245688438416\n",
      "Epoch 97, Loss: 0.8351783752441406\n",
      "Epoch 98, Loss: 0.8351323008537292\n",
      "Epoch 99, Loss: 0.8350863456726074\n",
      "Epoch 100, Loss: 0.8350405097007751\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):  # number of epochs\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train) # the liner index\n",
    "    loss = poisson_nll_loss(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1 == 0:  # print every 100 epochs\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[ 0.1144,  0.0591,  0.0363, -0.0234, -0.0331,  0.0234,  0.0042,  0.0778,\n",
      "         -0.0607,  0.0329,  0.0043,  0.0930, -0.0373,  0.0163, -0.0069, -0.0654,\n",
      "         -0.0276, -0.0438,  0.0172,  0.0405, -0.0676, -0.0195, -0.0185,  0.0292,\n",
      "          0.0843, -0.0662, -0.0750,  0.0204,  0.0678,  0.0853,  0.0416, -0.0180,\n",
      "          0.0500, -0.0008,  0.0454, -0.0146, -0.0568,  0.0249,  0.0283,  0.0454,\n",
      "          0.0639, -0.0489, -0.0442,  0.0788,  0.0266,  0.0544,  0.0533, -0.0238,\n",
      "          0.0917, -0.0546, -0.0019, -0.0618, -0.0693,  0.0072, -0.0689, -0.0681,\n",
      "         -0.0014, -0.0111, -0.0213,  0.0823, -0.0713,  0.0230,  0.0167, -0.0067,\n",
      "         -0.0458, -0.0031,  0.0464,  0.0140,  0.0736,  0.0423, -0.0470, -0.0199,\n",
      "          0.0314, -0.0045, -0.0694,  0.0891,  0.0715, -0.0007,  0.0555,  0.0116,\n",
      "         -0.0011,  0.0347, -0.0020, -0.0372, -0.0108, -0.0502,  0.0958, -0.0288,\n",
      "          0.0827,  0.0138, -0.0731,  0.0508,  0.0811,  0.0830,  0.0303, -0.0406,\n",
      "         -0.0363,  0.0280, -0.0104,  0.0881]])), ('linear.bias', tensor([-0.0076]))])\n"
     ]
    }
   ],
   "source": [
    "# print the coefficients of the model\n",
    "\n",
    "# print(model.state_dict()['linear.weight'])\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
